{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Puzzles in CUDA C++\n",
        "By Devin Shah - [@devinshah16](https://twitter.com/DevinShah16)\n",
        "\n",
        "Puzzles adapted from [Sasha Rush](http://rush-nlp.com/)\n",
        "\n",
        "GPUs are pretty cool.\n",
        "\n",
        "This notebook is a bit more of an advanced attempt to teach GPU programming interactively. Instead of using Python bindings (through Numba), we will be directly working with CUDA C++ bindings. In this notebook, we will just be focusing on the kernels, but in a later video, I will walk through how to instantiate the kernels, which is a bit harder than using Numba's built in executor.\n",
        "\n",
        "Be careful with pointers and dereferncing. All of these kernels do not need complicated technques; however, when we implement the kernel executors (coming soon), there are some complex techniques.\n",
        "\n",
        "I recommend doing Sasha's notebook first, as the visualization are much clearer and will help build intuition.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/srush/GPU-Puzzles/blob/main/GPU_puzzlers.ipynb)\n",
        "\n",
        "Make your own copy of this notebook in Colab, turn on GPU mode in the settings (`Runtime / Change runtime type`, then set `Hardware accelerator` to `GPU`), and\n",
        "then get to coding. ***You might get a warning saying that the GPU is not being used, but it is in fact being used. Ignore this warning. If using a free version, be careful of quotas.***\n",
        "\n",
        "\n",
        "Read the [CUDA C++ bindings guide ](https://docs.nvidia.com/cuda/pdf/CUDA_C_Programming_Guide.pdf)"
      ],
      "metadata": {
        "id": "cEdb9ewLcnlk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To test these, there is a single test case that has been created in the executors (in the gh repo). It runs on assertion statements, so your kernel will fail if the assertion statements fail. A compute sanitizer (developed by NVIDIA) is also run on your kernel so that you can debug memory issues and out of bounds issues. This is particularly helpful for shared memory."
      ],
      "metadata": {
        "id": "modblPrnyvkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dshah3/GPU-Puzzles.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t07XOkGYOljf",
        "outputId": "4d8ef248-4d35-415c-8e04-e6390ac9d186"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GPU-Puzzles'...\n",
            "remote: Enumerating objects: 220, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 220 (delta 124), reused 122 (delta 111), pack-reused 75\u001b[K\n",
            "Receiving objects: 100% (220/220), 1019.94 KiB | 5.02 MiB/s, done.\n",
            "Resolving deltas: 100% (154/154), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd GPU-Puzzles/GPU_puzzlers_exec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmYXrz5-O6ZF",
        "outputId": "41ba1fab-628f-4a0d-cc10-339afce0609c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GPU-Puzzles/GPU_puzzlers_exec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure `nvcc` is installed. If it is not, this notebook will not work."
      ],
      "metadata": {
        "id": "qtI4xlZ5rCA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH6Z1OfgOdHJ",
        "outputId": "d107105d-6ee8-44e6-96bf-1dd1d38cbaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 1: Map\n",
        "\n",
        "Implement a \"kernel\" (GPU function) that adds 10 to each position of vector `A`\n",
        "and stores it in vector `C`.  You have 1 thread per position.\n",
        "\n",
        "**Warning** This code looks like C++ but it is really CUDA C++! You have to be careful; for example, C++ supports indexing arrays like so: `A[i][j]`, but CUDA C++ allows for 1D indexing only, like so: `A[i * size + j]`.\n",
        "The puzzles only require doing simple operations, basically\n",
        "+, *, simple array indexing, for loops, and if statements.\n",
        "You are allowed to use local variables.\n",
        "If you get an\n",
        "error it is probably because you did something fancy :)."
      ],
      "metadata": {
        "id": "sX9cPANTmn9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile map_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void ScalarAdd(float* A, float* C) {\n",
        "  int i = threadIdx.x;\n",
        "\n",
        "  /// CODE HERE (approx 1 line) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnm9KmNTOv0i",
        "outputId": "2644079c-dbe0-45f3-a02a-de8b17a22e27"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting map_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o map_runner.o map_runner.cu\n",
        "!nvcc -c -o map_kernel.o map_kernel.cu\n",
        "!nvcc -o map map_runner.o map_kernel.o\n",
        "!./map\n",
        "!compute-sanitizer ./map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbgN7RuZPXss",
        "outputId": "47efd066-af71-4cc5-a74c-74ee9115d174"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar addition is successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Scalar addition is successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 2 - Zip\n",
        "Implement a kernel that adds together each position of `A` and `B` and stores it in `C`. You have 1 thread per position."
      ],
      "metadata": {
        "id": "qacs6IVBc6Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile zip_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void VecAdd(float* A, float* B, float* C) {\n",
        "  int i = threadIdx.x;\n",
        "\n",
        "  /// CODE HERE (approx 1 line) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn646k23Pgf-",
        "outputId": "1027c72b-cd49-4001-92b7-d91ec02d71d7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing zip_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o zip_runner.o zip_runner.cu\n",
        "!nvcc -c -o zip_kernel.o zip_kernel.cu\n",
        "!nvcc -o zip zip_runner.o zip_kernel.o\n",
        "!./zip\n",
        "!compute-sanitizer ./zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxivdZRnUWa3",
        "outputId": "786c5821-e2f6-45dd-caba-b4cd9ac3c5d3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector addition successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Vector addition successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 3 - Guards\n",
        "\n",
        "Implement a kernel that adds 10 to each position of `A` and stores it in `C`.\n",
        "You have more threads than positions."
      ],
      "metadata": {
        "id": "TK4z7Wu_ddPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile guards_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void Guards(float* A, float* C, int size) {\n",
        "  int i = threadIdx.x;\n",
        "\n",
        "  /// CODE HERE (approx 3 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_5IWX6_Ucut",
        "outputId": "47c6fd1f-f7f0-4cbc-8009-6ece3443e1f7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing guards_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o guards_runner.o guards_runner.cu\n",
        "!nvcc -c -o guards_kernel.o guards_kernel.cu\n",
        "!nvcc -o guards guards_runner.o guards_kernel.o\n",
        "!./guards\n",
        "!compute-sanitizer ./guards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9WJXffaUvGM",
        "outputId": "6a24f7c4-0d25-4f6d-be41-c06593821458"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guards successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Guards successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 4 - Map 2D\n",
        "\n",
        "Implement a kernel that adds 10 to each position of `A` and stores it in `C`.\n",
        "Input `A` is 2D and square. You have more threads than positions.\n",
        "\n",
        "1D indexing doesn't work for 2D arrays in CUDA C++. You can calculate the index from i and j by computing `i * size + j`."
      ],
      "metadata": {
        "id": "eN7sO1NneuOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile map2d_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void Map2D(float* A, float* C, float size) {\n",
        "  int local_i = threadIdx.x;\n",
        "  int local_j = threadIdx.y;\n",
        "\n",
        "  /// CODE HERE (approx 4 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vz2ubgdU3ha",
        "outputId": "8d6a220d-6ccd-4f69-c795-a1d8551f553c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing map2d_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o map2d_runner.o map2d_runner.cu\n",
        "!nvcc -c -o map2d_kernel.o map2d_kernel.cu\n",
        "!nvcc -o map2d map2d_runner.o map2d_kernel.o\n",
        "!./map2d\n",
        "!compute-sanitizer ./map2d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omGaIYihVVHl",
        "outputId": "ad277fcd-9dcd-46e4-dcb9-645d41518dc9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D mapping successful\n",
            "========= COMPUTE-SANITIZER\n",
            "2D mapping successful\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 5 - Broadcast\n",
        "\n",
        "Implement a kernel that adds `A` and `B` and stores it in `C`.\n",
        "Inputs `A` and `B` are vectors. You have more threads than positions."
      ],
      "metadata": {
        "id": "2YZo_quDfwjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile broadcast_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void Broadcast(float* A, float* B, float* C, int size) {\n",
        "  int local_i = threadIdx.x;\n",
        "  int local_j = threadIdx.y;\n",
        "\n",
        "  /// CODE HERE (approx 4 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fk-YMnrEVdmT",
        "outputId": "6b2c2679-8e77-42a8-88ab-d51e4a0b6e8d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing broadcast_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o broadcast_runner.o broadcast_runner.cu\n",
        "!nvcc -c -o broadcast_kernel.o broadcast_kernel.cu\n",
        "!nvcc -o broadcast broadcast_runner.o broadcast_kernel.o\n",
        "!./broadcast\n",
        "!compute-sanitizer ./broadcast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1aucnlAV2Sh",
        "outputId": "4846f281-f2f3-4d4c-aec9-06e083437c20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Broadcast successful\n",
            "========= COMPUTE-SANITIZER\n",
            "Broadcast successful\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 6 - Blocks\n",
        "\n",
        "Implement a kernel that adds 10 to each position of `A` and stores it in `C`.\n",
        "You have fewer threads per block than the size of `A`.\n",
        "\n",
        "*Tip: A block is a group of threads. The number of threads per block is limited, but we can\n",
        "have many different blocks. Variable `cuda.blockIdx` tells us what block we are in.*"
      ],
      "metadata": {
        "id": "Nii7pyQDf1Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile blocks_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void Blocks(float* A, float* C, float size) {\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "  /// CODE HERE (approx 3 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6FRDqGNV_gG",
        "outputId": "ad9ec01c-d6ab-42be-f30f-1e2ce64b8960"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting blocks_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o blocks_runner.o blocks_runner.cu\n",
        "!nvcc -c -o blocks_kernel.o blocks_kernel.cu\n",
        "!nvcc -o blocks blocks_runner.o blocks_kernel.o\n",
        "!./blocks\n",
        "!compute-sanitizer ./blocks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HufJKespWSam",
        "outputId": "5959bf00-7166-4333-a77a-865facbd1fba"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Blocks successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Blocks successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 7 - Blocks 2D\n",
        "\n",
        "Implement the same kernel in 2D.  You have fewer threads per block\n",
        "than the size of `A` in both directions."
      ],
      "metadata": {
        "id": "6AMsIvLzgqTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile map2d_block_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void Map2DBlock(float* A, float* C, float size) {\n",
        "  int local_i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int local_j = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "\n",
        "  /// CODE HERE (approx 4 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbKj-aWnWbP9",
        "outputId": "7eda3ac7-81de-432e-fc54-f16cb8755ed0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing map2d_block_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o map2d_block_runner.o map2d_block_runner.cu\n",
        "!nvcc -c -o map2d_block_kernel.o map2d_block_kernel.cu\n",
        "!nvcc -o map2d_block map2d_block_runner.o map2d_block_kernel.o\n",
        "!./map2d_block\n",
        "!compute-sanitizer ./map2d_block"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovRKwbPYWonu",
        "outputId": "6cf9eab6-0640-4f2b-e2c7-86decb2df111"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2D mapping successful\n",
            "========= COMPUTE-SANITIZER\n",
            "2D mapping successful\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 8 - Shared\n",
        "\n",
        "Implement a kernel that adds 10 to each position of `A` and stores it in `C`.\n",
        "You have fewer threads per block than the size of `A`.\n",
        "\n",
        "**Warning**: Each block can only have a *constant* amount of shared\n",
        " memory that threads in that block can read and write to. This needs\n",
        " to be a literal constant not a variable. After writing to\n",
        " shared memory you need to call `__syncthreads();` to ensure that\n",
        " threads do not cross."
      ],
      "metadata": {
        "id": "sDTC1DTXgriY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile shared_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void Shared(float* A, float* C, float size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  /// CODE HERE (approx 7 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMySSkNjW0s-",
        "outputId": "e851cb7d-633b-4dbd-8be8-bfe396f0b9af"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing shared_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o shared_runner.o shared_runner.cu\n",
        "!nvcc -c -o shared_kernel.o shared_kernel.cu\n",
        "!nvcc -o shared shared_runner.o shared_kernel.o\n",
        "!./shared\n",
        "!compute-sanitizer ./shared"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3py0JATXb7t",
        "outputId": "77f4f9c5-9737-4d5b-9088-234b9bd8bf95"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shared successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Shared successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 9 - Pooling\n",
        "\n",
        "Implement a kernel that sums together the last 3 position of `A` and stores it in `C`.\n",
        "You have 1 thread per position."
      ],
      "metadata": {
        "id": "6DcAN0Xtg3O7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile pooling_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void Pooling(float* A, float* C, float size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  /// CODE HERE (approx 7 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9-cDvQJXlpC",
        "outputId": "b68e87db-94ad-4077-983c-ccecf08dfd39"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing pooling_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o pooling_runner.o pooling_runner.cu\n",
        "!nvcc -c -o pooling_kernel.o pooling_kernel.cu\n",
        "!nvcc -o pooling pooling_runner.o pooling_kernel.o\n",
        "!./pooling\n",
        "!compute-sanitizer ./pooling"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDdN8WqDXsli",
        "outputId": "a4bc6f3c-e5ea-4897-de7e-6fcbc176cabf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pooling successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Pooling successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 10 - Dot Product\n",
        "\n",
        "Implement a kernel that computes the dot-product of `A` and `B` and stores it in `C`.\n",
        "You have 1 thread per position."
      ],
      "metadata": {
        "id": "PEbNGkoXhA0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dotproduct_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void DotProduct(float* A, float* B, float* C, float size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "  int i = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  /// CODE HERE (approx 11 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B86mKzRaX5e2",
        "outputId": "c9161763-95f1-41e0-ade9-f25ff29e5c21"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing dotproduct_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o dotproduct_runner.o dotproduct_runner.cu\n",
        "!nvcc -c -o dotproduct_kernel.o dotproduct_kernel.cu\n",
        "!nvcc -o dotproduct dotproduct_runner.o dotproduct_kernel.o\n",
        "!./dotproduct\n",
        "!compute-sanitizer ./dotproduct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoXnDcfJY_EA",
        "outputId": "28b44faa-218a-4967-c5f5-379b127b5e40"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dot product successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Dot product successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 11 - 1D Convolution\n",
        "\n",
        "Implement a kernel that computes a 1D convolution between `A` and `B` and stores it in `C`.\n",
        "You need to handle the general case.\n",
        "\n",
        "The shared memory is initialized to be enough to cover what is needed. In the kernel, the shared memory needs to be split into two different shared memories: `shared_a` and `shared_b`. The sizes of the shared memory will be clear as you develop the kernel."
      ],
      "metadata": {
        "id": "cMjCABZ0hFeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 1dconv_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "const int TPB = 8;\n",
        "const int MAX_CONV = 4;\n",
        "const int TPB_MAX_CONV = TPB + MAX_CONV;\n",
        "\n",
        "__global__ void Conv1D(float* A, float* B, float* C, int a_size, int b_size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  float* shared_a = ;\n",
        "  float* shared_b = ;\n",
        "\n",
        "  /// CODE HERE (approx 25 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MS-BHgiOZa3i",
        "outputId": "1ff54880-a477-4fc0-c98d-397523cd54d4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 1dconv_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o 1dconv_runner.o 1dconv_runner.cu\n",
        "!nvcc -c -o 1dconv_kernel.o 1dconv_kernel.cu\n",
        "!nvcc -o 1dconv 1dconv_runner.o 1dconv_kernel.o\n",
        "!./1dconv\n",
        "!compute-sanitizer ./1dconv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gja3CaPZaEL2",
        "outputId": "55e06614-a88a-4803-8281-0df7207197bf"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m1dconv_runner.cu(9)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"TPB_MAX_CONV\"\u001b[0m was declared but never referenced\n",
            "\n",
            "1D Convolution successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "1D Convolution successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 12 - Prefix Sum\n",
        "\n",
        "Implement a kernel that computes a sum over `A` and stores it in `C`.\n",
        "If the size of `A` is greater than the block size, only store the sum of\n",
        "each block.\n",
        "We will do this using the [parallel prefix sum](https://en.wikipedia.org/wiki/Prefix_sum) algorithm in shared memory.\n",
        "That is, each step of the algorithm should sum together half the remaining numbers.\n",
        "Follow this diagram:"
      ],
      "metadata": {
        "id": "z54-QI9rhJGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://user-images.githubusercontent.com/35882/178757889-1c269623-93af-4a2e-a7e9-22cd55a42e38.png\" width=\"400\">"
      ],
      "metadata": {
        "id": "nRvzTTF9hPO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile prefixsum_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void PrefixSum(float* A, float* C, int size) {\n",
        "  extern __shared__ float cache[];\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "\n",
        "  /// CODE HERE (approx 14 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLHWpLbAaNK5",
        "outputId": "a7d527c1-52c7-4d15-80f4-b826e13666a9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing prefixsum_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o prefixsum_runner.o prefixsum_runner.cu\n",
        "!nvcc -c -o prefixsum_kernel.o prefixsum_kernel.cu\n",
        "!nvcc -o prefixsum prefixsum_runner.o prefixsum_kernel.o\n",
        "!./prefixsum\n",
        "!compute-sanitizer ./prefixsum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxWEg8zSafnA",
        "outputId": "4c208153-04fb-41e9-8647-dde85f2e4cf9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prefix sum successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Prefix sum successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 13 - Axis Sum\n",
        "\n",
        "Implement a kernel that computes a sum over each column of `A` and stores it in `C`."
      ],
      "metadata": {
        "id": "XVEwclS8hjGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile axis_sum_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void AxisSum(float* A, float* C, int size) {\n",
        "  extern __shared__ float cache[];\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int local_i = threadIdx.x;\n",
        "  int batch = blockIdx.y;\n",
        "\n",
        "  /// CODE HERE (approx 14 lines) ///\n",
        "\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di11r1QgasvO",
        "outputId": "0017bd11-ff0b-40e6-d46f-996f6bf022a0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing axis_sum_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o axis_sum_runner.o axis_sum_runner.cu\n",
        "!nvcc -c -o axis_sum_kernel.o axis_sum_kernel.cu\n",
        "!nvcc -o axis_sum axis_sum_runner.o axis_sum_kernel.o\n",
        "!./axis_sum\n",
        "!compute-sanitizer ./axis_sum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnLqqSUsa6-e",
        "outputId": "ef5c00ab-5980-4793-d4e7-122cf8d39009"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Axis sum successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Axis sum successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puzzle 14 - Matrix Multiply!\n",
        "\n",
        "Implement a kernel that multiplies square matrices (with the same size) `A` and `B` and\n",
        "stores the result in `C`.\n",
        "\n",
        "*Tip: The most efficient algorithm here will copy a block into\n",
        " shared memory before computing each of the individual row-column\n",
        " dot products. This is easy to do if the matrix fits in shared\n",
        " memory.  Do that case first. Then update your code to compute\n",
        " a partial dot-product and iteratively move the part you\n",
        " copied into shared memory.*"
      ],
      "metadata": {
        "id": "6RGRsxqYzl7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matmul_kernel.cu\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "const int TPB = 3;\n",
        "\n",
        "__global__ void Matmul(float* A, float* B, float* C, int size) {\n",
        "  extern __shared__ float sharedMem[];\n",
        "\n",
        "  int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  int j = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "  int local_i = threadIdx.x;\n",
        "  int local_j = threadIdx.y;\n",
        "\n",
        "  float* a_shared = ;\n",
        "  float* b_shared = ;\n",
        "\n",
        "  /// CODE HERE (approx 20 lines) ///\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik-qTdTUbKo0",
        "outputId": "fd47e3d7-0893-4bce-f9d2-d07fc19ee590"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matmul_kernel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -c -o matmul_runner.o matmul_runner.cu\n",
        "!nvcc -c -o matmul_kernel.o matmul_kernel.cu\n",
        "!nvcc -o matmul matmul_runner.o matmul_kernel.o\n",
        "!./matmul\n",
        "!compute-sanitizer ./matmul"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chwYE178be8B",
        "outputId": "d4c3be63-b5a5-4be8-aa36-2093727d8994"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix multiplication successful!\n",
            "========= COMPUTE-SANITIZER\n",
            "Matrix multiplication successful!\n",
            "========= ERROR SUMMARY: 0 errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QrRRDBZbbnsa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
